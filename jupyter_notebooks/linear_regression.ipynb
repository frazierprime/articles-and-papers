{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed data for experiments\n",
    "# Input data. We call reshape on x because this array is required to be two-dimensional (read: should ahve one column and as many rows as necessary).\n",
    "# x.shape = (6, 1)\n",
    "x = numpy.array([5, 15, 25, 35, 45, 55]).reshape((-1, 1))\n",
    "\n",
    "# Output data:\n",
    "# y.shape = (6,)\n",
    "y = numpy.array([5, 20, 14, 32, 22, 38])\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional parameters to this model constructor:\n",
    "# fit_intercept - (default: True). Boolean to determine whether or not to calculate the intercept b0 (True) or consider it equal to 0 (False)\n",
    "# normalize - (default: False). Normalize input variables?\n",
    "# copy_X - (default: True). copy (True) or overwrite (False) the input variables.\n",
    "# n_jobs - (integer or None (default)). Represents the number of jobs used in parallel computation. \n",
    "linear_regression_model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the optimal values of the weights b0 and b1, using the existing input and output (x and y).\n",
    "linear_regression_model.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the coefficient of determination (R^2).\n",
    "# In the walkthrough, the author has now called the x and y variables the input and output (respectively) and with this step, called it\n",
    "# the predictor and the regressor. I guess depending on the context there is different terminology for these variables?\n",
    "r_squared = linear_regression_model.score(x, y)\n",
    "print(f'coefficient of determination: {r_squared}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The attributes of this model are .intercept_ (represents the coefficient b0) and .coef_ which represents b1.\n",
    "# The intercept is a scalar, and the coefficient is an array. \n",
    "\n",
    "# The value of the intercept (b0) illustrates that the model predicts a specific response when x is zero.\n",
    "# The coefficient represents the predict response if x is increased by one.\n",
    "print(f'intercept: {linear_regression_model.intercept_}')\n",
    "print(f'coefficient: {linear_regression_model.coef_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depending on the shape and needs of the data, it may be necessary to pass these variables as two-dimensional arrays, which changes the \n",
    "# shape of the intercept and coefficient.\n",
    "different_model_example = LinearRegression().fit(x, y.reshape((-1, 1)))\n",
    "print(f'intercept: {different_model_example.intercept_}')\n",
    "print(f'coefficient: {different_model_example.coef_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When applying .predict(), we pass the regressor as the argument to get the corresponding predicted response.\n",
    "y_predictions = linear_regression_model.predict(x)\n",
    "print(f'predicted response: {y_predictions}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another formula for generating the predictions.\n",
    "# This is nearly identical, except in the output. \n",
    "# The dimensions of the output goes from a single dimension to two.\n",
    "y_pred = linear_regression_model.intercept_ + linear_regression_model.coef_ * x\n",
    "print(f'predicted response: {y_pred}')\n",
    "\n",
    "# If the number of dimensions of x is reduced to one, the two prediction approaches will yield the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In practice, regression models are often applied for forecasting values. \n",
    "# This means that fitted models can be used to calculate outputs based on some new input.\n",
    "x_new = numpy.arange(6).reshape((-1, 1))\n",
    "print(x_new)\n",
    "new_prediction = linear_regression_model.predict(x_new)\n",
    "print(new_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-dimensional linear regression.\n",
    "multi_x = [[0, 1], [5, 1], [15, 2], [25, 5], [35, 11], [45, 15], [55, 34], [60, 35]]\n",
    "multi_y = [4, 5, 20, 14, 32, 22, 38, 43]\n",
    "multi_x = numpy.array(multi_x)\n",
    "multi_y = numpy.array(multi_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_linear_regression_model = LinearRegression().fit(multi_x, multi_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model properties\n",
    "# .intercept_ holds the bias b0 (again, another name for this variable. Need to standardize the naming scheme in this notebook).\n",
    "# .coef_ is now an array containing the coefficients b1 and b2 (this is a multi-dimensional model, so we have multiple coefficients).\n",
    "r_sq = multi_linear_regression_model.score(multi_x, multi_y)\n",
    "print(f'coefficient of determination: {r_sq}')\n",
    "print(f'intercept: {multi_linear_regression_model.intercept_}')\n",
    "print(f'slope: {multi_linear_regression_model.coef_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "multi_y_pred = multi_linear_regression_model.predict(multi_x)\n",
    "print(f'predicted response: {multi_y_pred}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply this model to a new dataset\n",
    "new_dataset_x = numpy.arange(12).reshape((-1, 2))\n",
    "print(new_dataset_x)\n",
    "new_predictions = multi_linear_regression_model.predict(new_dataset_x)\n",
    "print(f'predictions: {new_predictions}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial regression with scikit-learn\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# poly_x needs to be a two-dimensional\n",
    "# Interestingly, adding values to these arrays has side-effects for the transformations in the following cells.\n",
    "# TODO: Dig into how the fit and transform computations are done. Start here: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html\n",
    "poly_x = numpy.array([5, 15, 25, 35, 45, 55, 2, 106, 72, 1]).reshape((-1, 1))\n",
    "poly_y = numpy.array([15, 11, 2, 8, 25, 32, 7, 123, 98, 100])\n",
    "poly_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to include x^2 (and depending on the case, other terms) as additional features when implementing polynomial regression.\n",
    "# Here, we transform the input variable poly_x to contain an additional column with the values of x^2 (and eventually more features).\n",
    "\n",
    "# This is an instance of PolynomialFeatures that can be used ot transform the input x.\n",
    "# Optional parameters to this model constructor:\n",
    "# degree - (default: 2) represents the degree of the polynomial regression function.\n",
    "# interaction_only - (default: False) Whether to include only interaction features (True) or all features (False).\n",
    "# include_bias - (default: True) Whether or not to include the bias (intercept) column of ones (True) or not (False).\n",
    "transformer = PolynomialFeatures(degree=2, include_bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before applying the transformation, we need to fit it.\n",
    "transformer.fit(poly_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Transform the input\n",
    "x_ = transformer.transform(poly_x)\n",
    "x_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is possible to replace the last three statements with the fit_transformation() function.\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(poly_x)\n",
    "x_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model and fit it\n",
    "polynomial_linear_regression = LinearRegression().fit(x_, poly_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_r_sq = polynomial_linear_regression.score(x_, poly_y)\n",
    "print(f'coefficient for determination: {poly_r_sq}')\n",
    "print(f'intercept: {polynomial_linear_regression.intercept_}')\n",
    "print(f'coefficients: {polynomial_linear_regression.coef_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function to predict is the same as with the simpler linear regression. It requires the transformation\n",
    "# for the polynomial \n",
    "poly_y_prediction = polynomial_linear_regression.predict(x_)\n",
    "print(f'predicted response: {poly_y_prediction}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for a new set of data.\n",
    "new_dataset_x = numpy.arange(12).reshape((-1, 2))\n",
    "new_predictions = polynomial_linear_regression.predict(new_dataset_x)\n",
    "new_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the same methods for polynomial regression for several input variables\n",
    "x = [[0, 1], [5, 1], [15, 2], [25, 5], [35, 11], [45, 15], [55, 34], [60, 35]]\n",
    "y = [4, 5, 20, 14, 32, 22, 38, 43]\n",
    "x, y = numpy.array(x), numpy.array(y)\n",
    "# Transform the input data\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x)\n",
    "\n",
    "model = LinearRegression().fit(x_, y)\n",
    "\n",
    "# Get results\n",
    "r_sq = model.score(x_, y)\n",
    "intercept, coefficients = model.intercept_, model.coef_\n",
    "\n",
    "# Predict\n",
    "y_prediction = model.predict(x_)\n",
    "\n",
    "print(f'coefficient: {r_sq}')\n",
    "print(f'intercept: {intercept}')\n",
    "print(f'coefficients: {coefficients}')\n",
    "print(f'predicted response: {y_prediction}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced linear regression with statsmodels\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_x = [[0, 1], [5, 1], [15, 2], [25, 5], [35, 11], [45, 15], [55, 34], [60, 35]]\n",
    "stats_y = [4, 5, 20, 14, 32, 22, 38, 43]\n",
    "stats_x, stats_y = numpy.array(stats_x), numpy.array(stats_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_x = sm.add_constant(stats_x)\n",
    "stats_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This regression model is based on ordinary least squares (OLS)\n",
    "ols_regression_model = sm.OLS(stats_y, stats_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = ols_regression_model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
